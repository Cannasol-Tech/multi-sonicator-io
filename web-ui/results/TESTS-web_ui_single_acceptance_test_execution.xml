<testsuite name="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" tests="7" errors="7" failures="0" skipped="0" time="0.006607" timestamp="2025-09-16T13:44:35.730476" hostname="runnervmf4ws1"><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="Execute single acceptance test and wait for completion" status="error" time="0.00094"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @smoke @single-test @execution
  Scenario: Execute single acceptance test and wait for completion
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I am on the Test Automation panel ... undefined in 0.000s
    And acceptance test scenarios are loaded ... skipped in 0.000s
    When I select a single test scenario "Hardware Basic Connectivity" ... skipped in 0.000s
    And I click the "Run Selected" button ... skipped in 0.000s
    Then the test execution should start ... skipped in 0.000s
    And I should see a progress indicator showing test execution ... skipped in 0.000s
    And the execution status should show "running" ... skipped in 0.000s
    And I should wait for the test to finish ... skipped in 0.000s
    And the final status should be either "passed" or "failed" ... skipped in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="Verify single test results are displayed correctly" status="error" time="0.000945"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @single-test @results-display
  Scenario: Verify single test results are displayed correctly
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I have executed a single acceptance test ... skipped in 0.000s
    And the test has completed ... skipped in 0.000s
    When I view the test results ... skipped in 0.000s
    Then I should see the detailed test results displayed ... skipped in 0.000s
    And the results should show the scenario name and description ... undefined in 0.000s
    And the results should display the execution time ... undefined in 0.000s
    And the results should show the final status (passed/failed) ... undefined in 0.000s
    And if failed, error details should be visible ... undefined in 0.000s
    And all test steps should be listed with their individual status ... undefined in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="Verify real-time progress updates during single test execution" status="error" time="0.000961"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @single-test @real-time-updates
  Scenario: Verify real-time progress updates during single test execution
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I am on the Test Automation panel ... undefined in 0.000s
    And I have selected a single test scenario ... undefined in 0.000s
    When I start the test execution ... undefined in 0.000s
    Then I should see real-time progress updates ... undefined in 0.000s
    And the current step being executed should be highlighted ... undefined in 0.000s
    And step completion should be indicated as it happens ... undefined in 0.000s
    And the overall progress percentage should update ... undefined in 0.000s
    And any step failures should be immediately visible ... undefined in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="Export single test results" status="error" time="0.000931"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @single-test @results-export
  Scenario: Export single test results
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I have completed a single acceptance test ... skipped in 0.000s
    And the results are displayed ... undefined in 0.000s
    When I click the "Export Results" button ... undefined in 0.000s
    And I select "JSON" format ... undefined in 0.000s
    Then the test results should be exported as a JSON file ... undefined in 0.000s
    And the exported file should contain all test details ... undefined in 0.000s
    And the file should include scenario information, steps, and outcomes ... undefined in 0.000s
    And the export should be downloadable ... undefined in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="Handle single test execution errors gracefully" status="error" time="0.000936"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @single-test @error-handling
  Scenario: Handle single test execution errors gracefully
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I am on the Test Automation panel ... undefined in 0.000s
    And I select a test scenario that will fail ... undefined in 0.000s
    When I run the selected test ... undefined in 0.000s
    And the test fails during execution ... undefined in 0.000s
    Then I should see a clear error message ... undefined in 0.000s
    And the error details should be displayed ... undefined in 0.000s
    And the failed step should be highlighted ... undefined in 0.000s
    And there should be an option to retry the test ... undefined in 0.000s
    And the interface should remain stable after the error ... undefined in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="Stop single test execution mid-run" status="error" time="0.000937"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @single-test @test-interruption
  Scenario: Stop single test execution mid-run
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I am running a single acceptance test ... undefined in 0.000s
    And the test is currently executing ... undefined in 0.000s
    When I click the "Stop Execution" button ... undefined in 0.000s
    Then the test execution should stop immediately ... undefined in 0.000s
    And the status should show "stopped" or "cancelled" ... undefined in 0.000s
    And any partial results should be preserved ... undefined in 0.000s
    And I should be able to start a new test execution ... undefined in 0.000s
    And the interface should return to the ready state ... undefined in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase><testcase classname="web_ui_single_acceptance_test_execution.Single Acceptance Test Web-UI Execution and Results Verification" name="View detailed information for individual test steps" status="error" time="0.000957"><error type="AttributeError" message="'Context' object has no attribute 'backend_url'">
<![CDATA[
Failing step: Given the web-ui is running in simulation mode ... error in 0.001s
Location: features/web_ui_single_acceptance_test_execution.feature:8
Traceback (most recent call last):
  File "/home/runner/.local/lib/python3.12/site-packages/behave/model.py", line 1991, in run
    match.run(runner.context)
  File "/home/runner/.local/lib/python3.12/site-packages/behave/matchers.py", line 105, in run
    self.func(context, *args, **kwargs)
  File "steps/web_ui_acceptance_steps.py", line 41, in step_web_ui_running_simulation_mode
    response = requests.get(f"{context.backend_url}/api/health")
                               ^^^^^^^^^^^^^^^^^^^
  File "/home/runner/.local/lib/python3.12/site-packages/behave/runner.py", line 430, in __getattr__
    raise AttributeError(msg)
AttributeError: 'Context' object has no attribute 'backend_url'
]]>
</error><system-out>
<![CDATA[
@scenario.begin

  @single-test @detailed-step-view
  Scenario: View detailed information for individual test steps
    Given the web-ui is running in simulation mode ... error in 0.001s
    And the Test Automation panel is loaded ... skipped in 0.000s
    And acceptance test scenarios are loaded from the backend ... skipped in 0.000s
    And the hardware mock is enabled ... skipped in 0.000s
    Given I have completed a single acceptance test ... skipped in 0.000s
    And the results are displayed ... undefined in 0.000s
    When I click on a specific test step in the results ... undefined in 0.000s
    Then I should see detailed step information ... undefined in 0.000s
    And the step should show its type (Given/When/Then) ... undefined in 0.000s
    And the step description should be fully visible ... undefined in 0.000s
    And any pin interactions should be listed ... undefined in 0.000s
    And step execution time should be displayed ... undefined in 0.000s
    And for failed steps, detailed error information should be shown ... undefined in 0.000s

@scenario.end
--------------------------------------------------------------------------------
]]>
</system-out></testcase></testsuite>