name: Multi-Sonicator Test Pipeline

on:
  push:
    branches: [ master, develop ]
  pull_request:
    branches: [ master, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PLATFORMIO_CORE_DIR: ~/.platformio

jobs:
  # Configuration validation job
  validate-config:
    runs-on: ubuntu-latest
    name: Validate Configuration
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-testing.txt
        
    - name: Validate HIL configuration
      run: |
        python3 scripts/validate_hil_config.py
        
    - name: Analyze pending scenarios
      run: |
        python3 scripts/manage_pending_scenarios.py

  # Unit testing job - Updated to use make ci
  unit-tests:
    runs-on: ubuntu-latest
    name: CI Pipeline (Unit Tests Only)
    needs: validate-config
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y gcc g++ lcov
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-testing.txt
        
    - name: Install PlatformIO
      run: |
        pip install platformio
        
    - name: Run CI Pipeline
      run: |
        make ci
        
    - name: Upload CI reports
      uses: actions/upload-artifact@v4
      with:
        name: ci-reports
        path: |
          coverage/
          final/
        retention-days: 30
        
    - name: Check coverage requirement
      run: |
        python3 -c "
        import json
        with open('coverage/coverage.json', 'r') as f:
            data = json.load(f)
        coverage = data['overall']['coverage_percentage']
        print(f'Overall coverage: {coverage}%')
        if coverage < 90.0:
            print('‚ùå Coverage requirement not met (<90%)')
            exit(1)
        else:
            print('‚úÖ Coverage requirement met (‚â•90%)')
        "

  # Acceptance testing job (REMOVED - Manual Only)
  # Acceptance tests are now run manually only as per issue requirements
  # This job has been removed to ensure CI pipeline only runs unit tests
  validate-acceptance-syntax:
    runs-on: ubuntu-latest
    name: Validate BDD Syntax (No Execution)
    needs: validate-config
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-testing.txt
        
    - name: Validate BDD syntax only (no execution)
      run: |
        # Only validate BDD syntax without hardware execution
        cd test/acceptance
        behave --dry-run features/
        
    - name: Generate BDD scenario report
      run: |
        python3 scripts/manage_pending_scenarios.py
        
    - name: Upload BDD validation reports
      uses: actions/upload-artifact@v4
      with:
        name: bdd-validation-reports
        path: |
          test/acceptance/logs/
          test/acceptance/pending_scenarios.yaml
        retention-days: 30

  # Integration and reporting job
  integration-report:
    runs-on: ubuntu-latest
    name: Integration Report
    needs: [unit-tests, validate-acceptance-syntax]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-testing.txt
        
    - name: Download CI reports
      uses: actions/download-artifact@v3
      with:
        name: ci-reports
        path: ./
      continue-on-error: true
        
    - name: Download BDD validation reports
      uses: actions/download-artifact@v3
      with:
        name: bdd-validation-reports
        path: test/acceptance/
      continue-on-error: true
        
    - name: Generate final integration report
      run: |
        python3 scripts/generate_traceability_report.py
        
    - name: Upload final reports
      uses: actions/upload-artifact@v4
      with:
        name: integration-reports
        path: |
          coverage/traceability_report.html
          coverage/traceability_report.json
        retention-days: 90
        
    - name: Create test summary
      run: |
        echo "## üß™ CI Pipeline Summary (Unit Tests Only)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        if [ -f "coverage/coverage.json" ]; then
          COVERAGE=$(python3 -c "import json; data=json.load(open('coverage/coverage.json')); print(f\"{data['overall']['coverage_percentage']:.1f}%\")")
          echo "### Unit Tests" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage**: $COVERAGE" >> $GITHUB_STEP_SUMMARY
          echo "- **Framework**: Unity Test Framework" >> $GITHUB_STEP_SUMMARY
          echo "- **Pipeline**: CI runs unit tests only" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "final/executive-report.json" ]; then
          echo "### Executive Report" >> $GITHUB_STEP_SUMMARY
          echo "- **Generated**: ‚úÖ Available in artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- **Type**: Unit tests only (CI pipeline)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "test/acceptance/pending_scenarios.yaml" ]; then
          echo "### Acceptance Tests" >> $GITHUB_STEP_SUMMARY
          echo "- **Framework**: Behave BDD" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: Syntax validated only" >> $GITHUB_STEP_SUMMARY
          echo "- **Execution**: Manual only (not run in CI)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### Reports Generated" >> $GITHUB_STEP_SUMMARY
        echo "- Executive report (unit tests only)" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage reports (HTML/JSON)" >> $GITHUB_STEP_SUMMARY
        echo "- Unit test summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Note" >> $GITHUB_STEP_SUMMARY
        echo "**Acceptance tests are now run manually only.** This CI pipeline focuses on unit tests for faster feedback and hardware independence." >> $GITHUB_STEP_SUMMARY

  # Hardware-in-the-loop testing (only on self-hosted runners with hardware)
  hil-tests:
    runs-on: self-hosted
    name: Hardware-in-the-Loop Tests
    needs: [unit-tests]
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[hil]')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-testing.txt
        
    - name: Check hardware availability
      run: |
        python3 -c "
        import serial.tools.list_ports
        ports = list(serial.tools.list_ports.comports())
        print(f'Available ports: {[p.device for p in ports]}')
        if not ports:
            print('‚ö†Ô∏è No hardware detected - skipping HIL tests')
            exit(0)
        "
      continue-on-error: true
        
    - name: Run HIL acceptance tests
      run: |
        make test-acceptance
      timeout-minutes: 30
      continue-on-error: true
        
    - name: Upload HIL test results
      uses: actions/upload-artifact@v4
      with:
        name: hil-test-results
        path: |
          test/acceptance/logs/
          test/acceptance/reports/
        retention-days: 30
      if: always()
