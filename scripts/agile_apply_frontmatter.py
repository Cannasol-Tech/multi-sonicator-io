#!/usr/bin/env python3
"""
Add condensed agent metadata frontmatter to story markdown files.

- Targets the following directories (recursive):
  - docs/agile/stories/
  - docs/agile/stories/ARCHIVE/
  - docs/agile/stories/__COMPLETE__/
  - docs/agile/stories/

- If a file already has YAML frontmatter (starts with '---'), it is skipped by default
  to avoid accidental overwrites. Use --force to try merging minimal required fields.

- Provenance banner is read from docs/sop/provenance-tags.md frontmatter at
  key banners.header.ai_generated. If unavailable, a safe fallback is used.

Usage:
  python3 scripts/agile_apply_frontmatter.py [--dry-run] [--force]
"""
from __future__ import annotations

import argparse
import datetime
import json
import os
import re
import sys
from typing import Dict, Optional, Tuple

RE_FRONTMATTER = re.compile(r"^---\n.*?\n---\n", re.DOTALL)
RE_HEADING = re.compile(r"^#\s*(.+)", re.MULTILINE)
RE_ID_LINE = re.compile(r"^\*\*Story ID\*\*:\s*(S-?[0-9]+(?:\.[0-9]+)?)", re.MULTILINE)
RE_OWNER_LINE = re.compile(r"^\*\*Owner\*\*:\s*(.+)$", re.MULTILINE)
RE_UPDATED_LINE = re.compile(r"^\*\*Updated\*\*:\s*([0-9]{4}-[0-9]{2}-[0-9]{2})", re.MULTILINE)
RE_STATUS_SECTION = re.compile(r"^##\s*Status\s*$([\s\S]*?)(?:^##\s|\Z)", re.MULTILINE)

DEFAULT_BANNER = "<!-- Generated by •∆• ~•Axovia•ƒløw™•~ -->"
PROVENANCE_PATH = os.path.join("docs", "sop", "provenance-tags.md")

TARGET_DIRS = [
    os.path.join("docs", "stories"),
    os.path.join("docs", "stories", "ARCHIVE"),
    os.path.join("docs", "stories", "__COMPLETE"),
    os.path.join("docs", "agile", "stories"),
]


def read_provenance_banner() -> str:
    path = PROVENANCE_PATH
    if not os.path.exists(path):
        return DEFAULT_BANNER
    try:
        with open(path, "r", encoding="utf-8") as f:
            text = f.read()
        # crude frontmatter extraction
        if not text.startswith("---"):
            return DEFAULT_BANNER
        end = text.find("\n---", 3)
        if end == -1:
            return DEFAULT_BANNER
        fm = text[3:end].strip()  # YAML-ish, but we'll regex for the key
        m = re.search(r"banners:\s*\n\s*header:\s*\n\s*ai_generated:\s*\"(.*?)\"", fm)
        if m:
            return m.group(1)
        # try single-quoted
        m = re.search(r"banners:\s*\n\s*header:\s*\n\s*ai_generated:\s*'(.*?)'", fm)
        if m:
            return m.group(1)
        # try non-quoted
        m = re.search(r"banners:\s*\n\s*header:\s*\n\s*ai_generated:\s*(.*)", fm)
        if m:
            return m.group(1).strip()
    except Exception:
        return DEFAULT_BANNER
    return DEFAULT_BANNER


def infer_metadata(markdown: str, file_path: str) -> Dict[str, str]:
    meta: Dict[str, str] = {}

    # id
    m = RE_ID_LINE.search(markdown)
    if m:
        meta["id"] = m.group(1).replace(" ", "").replace("S-", "S-")
    else:
        # Try from filename prefix like "1.4.single-..." -> S-1.4
        base = os.path.basename(file_path)
        m = re.match(r"([0-9]+\.[0-9]+)", base)
        if m:
            meta["id"] = f"S-{m.group(1)}"
        else:
            meta["id"] = "S-UNKNOWN"

    # title (from first H1 heading)
    m = RE_HEADING.search(markdown)
    if m:
        title = m.group(1).strip()
        # Remove leading "Story X.Y:" if present
        title = re.sub(r"^Story\s*[0-9]+\.[0-9]+:\s*", "", title)
        meta["title"] = title
    else:
        meta["title"] = os.path.splitext(os.path.basename(file_path))[0]

    # owner
    m = RE_OWNER_LINE.search(markdown)
    if m:
        meta["owner"] = m.group(1).strip()

    # updated_at
    m = RE_UPDATED_LINE.search(markdown)
    if m:
        meta["updated_at"] = m.group(1)

    # status (from Status section body first non-empty line)
    m = RE_STATUS_SECTION.search(markdown)
    if m:
        body = m.group(1)
        for line in body.splitlines():
            line = line.strip().strip("*#-")
            if line:
                meta["status"] = normalize_status(line)
                break

    return meta


STATUS_MAP = {
    "ready for review": "in_review",
    "in review": "in_review",
    "completed": "done",
    "complete": "done",
    "done": "done",
    "backlog": "backlog",
    "ready": "ready",
    "in progress": "in_progress",
    "blocked": "blocked",
    "archived": "archived",
}


def normalize_status(text: str) -> str:
    t = re.sub(r"\s+", " ", text).strip().lower()
    return STATUS_MAP.get(t, t.replace(" ", "_"))


def already_has_frontmatter(text: str) -> bool:
    return text.startswith("---\n")


def build_frontmatter(meta: Dict[str, str], banner: str) -> str:
    id_ = meta.get("id", "S-UNKNOWN")
    title = meta.get("title", "<Title>")
    status = meta.get("status", "backlog")
    owner = meta.get("owner", "")
    updated = meta.get("updated_at", datetime.date.today().isoformat())
    fm = [
        "---",
        f"# {banner}",
        f"id: {id_}",
        f"title: {title}",
        f"status: {status}",
    ]
    if owner:
        fm.append(f"owner: {owner}")
    fm.extend([
        # assignee optional, omit if unknown
        f"updated_at: {updated}",
        "version: 1.0",
        "provenance:",
        f"  banner: \"{banner}\"",
        "---",
        "",
    ])
    return "\n".join(fm)


def process_file(path: str, banner: str, dry_run: bool, force: bool) -> Tuple[bool, str]:
    with open(path, "r", encoding="utf-8") as f:
        text = f.read()

    if already_has_frontmatter(text) and not force:
        return False, f"SKIP (frontmatter exists): {path}"

    # If force, do not try a full merge—just ensure minimal required keys by prepending
    # a condensed frontmatter, but keep original for safety as backup .bak
    meta = infer_metadata(text, path)
    fm = build_frontmatter(meta, banner)

    new_text = fm + text if not already_has_frontmatter(text) else fm + RE_FRONTMATTER.sub("", text, count=1)

    if dry_run:
        return True, f"WOULD UPDATE: {path}"

    # backup
    bak_path = path + ".bak"
    try:
        if not os.path.exists(bak_path):
            with open(bak_path, "w", encoding="utf-8") as fb:
                fb.write(text)
    except Exception as e:
        return False, f"ERROR making backup for {path}: {e}"

    try:
        with open(path, "w", encoding="utf-8") as f:
            f.write(new_text)
    except Exception as e:
        return False, f"ERROR writing {path}: {e}"

    return True, f"UPDATED: {path}"


def main() -> int:
    parser = argparse.ArgumentParser(description="Apply condensed story frontmatter with provenance banner")
    parser.add_argument("--dry-run", action="store_true", help="List changes without writing files")
    parser.add_argument("--force", action="store_true", help="Replace existing frontmatter with condensed version")
    args = parser.parse_args()

    banner = read_provenance_banner()

    total = 0
    updated = 0
    skipped = 0
    errors = 0
    messages = []

    for root_dir in TARGET_DIRS:
        if not os.path.isdir(root_dir):
            continue
        for r, _dirs, files in os.walk(root_dir):
            for name in files:
                if not name.lower().endswith(".md"):
                    continue
                path = os.path.join(r, name)
                total += 1
                ok, msg = process_file(path, banner, args.dry_run, args.force)
                messages.append(msg)
                if ok:
                    if msg.startswith("UPDATED") or msg.startswith("WOULD UPDATE"):
                        updated += 1
                else:
                    if msg.startswith("SKIP"):
                        skipped += 1
                    else:
                        errors += 1

    for m in messages:
        print(m)

    print("\nSummary:")
    print(f"  Found:    {total} .md files")
    print(f"  Updated:  {updated}")
    print(f"  Skipped:  {skipped}")
    print(f"  Errors:   {errors}")

    return 0 if errors == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
