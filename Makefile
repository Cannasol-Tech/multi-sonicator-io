# Multi-Sonicator I/O Controller Makefile
# Uses Arduino Framework with PlatformIO for ATmega32A development
# Unity Tests for Unit Testing, Behave for Acceptance Testing

# Declare phony targets (targets that don't create files)
.PHONY: build clean upload install-deps check-deps check-pio check-arduino-cli test-unit test-acceptance test-all ci ci-test
.PHONY: monitor-device upload-to-device upload-harness setup-arduino-isp check-arduino-isp
.PHONY: hardware-sandbox acceptance-setup acceptance-clean acceptance-test-basic acceptance-test-gpio acceptance-test-adc
.PHONY: acceptance-test-pwm acceptance-test-modbus acceptance-test-power generate-release-artifacts test-integration
.PHONY: test-unit-communication test-unit-hal test-unit-control test-unit-sonicator validate-config generate-traceability-report manage-pending-scenarios update-pending-scenarios ci-local
.PHONY: web-ui-install web-ui-dev web-ui-build web-ui-sandbox web-ui-test web-ui-test-acceptance web-ui-clean web-ui-stop
.PHONY: web-ui-docker-build web-ui-docker-dev web-ui-docker-prod web-ui-docker-stop web-ui-docker-clean
.PHONY: validate-traceability check-compliance update-standards sync-standards check-standards generate-executive-report generate-coverage-report generate-complete-executive-report coverage update-tools install-tools check-tools run-tool
.PHONY: validate-dod check-dod-compliance enforce-dod-gate validate-story-completion

#  Make Targets

.PHONY: traceability

# Lightweight BDD traceability scan (ensures every @TODO has a matching @trace)
traceability: check-deps
	@echo "ğŸ” Running BDD traceability scan (@TODO vs @trace)..."
	@python3 scripts/update_traceability.py
	@echo "âœ… BDD traceability scan complete"

# Python virtual environment wrapper for consistency
PYTHON_VENV := . web-ui/venv/bin/activate && python
PYTHON_VENV_PIP := . web-ui/venv/bin/activate && pip
# Prefer a stable interpreter inside venv (python3.13 if present, else python)
VENV_PY := $(shell [ -x web-ui/venv/bin/python3.13 ] && echo web-ui/venv/bin/python3.13 || echo web-ui/venv/bin/python)

# Verbosity control for acceptance auto-setup (1 = silent redirects)
ACCEPT_SILENT ?= 1
ifeq ($(ACCEPT_SILENT),1)
REDIR := >/dev/null 2>&1
else
REDIR :=
endif


# Python dependency installation
install-deps: update-standards
	@echo "ğŸ“¦ Installing Python dependencies..."
	@echo "ğŸ”§ Setting up Python virtual environment..."
	@python3 -m venv web-ui/venv 2>/dev/null || true
	@echo "ğŸ“¦ Installing dependencies in virtual environment..."
	@web-ui/venv/bin/python -m pip install --upgrade pip
	@web-ui/venv/bin/python -m pip install -r config/requirements-testing.txt
	@web-ui/venv/bin/python -m pip install -r config/tools-requirements.txt
	@echo "âœ… Python dependencies installed in virtual environment"

# Check and install dependencies if needed
check-deps:
	@echo "ğŸ” Checking Python dependencies..."
	@if [ ! -d "web-ui/venv" ]; then \
		echo "âš ï¸  Python venv missing; creating local virtualenv at web-ui/venv"; \
		python3 -m venv web-ui/venv >/dev/null 2>&1 || true; \
	fi
	@$(PYTHON_VENV) -c "import behave, serial, pytest, yaml" 2>/dev/null && echo "âœ… All Python dependencies available" || \
		( echo "âš ï¸  Python test deps missing; installing all dependencies in virtualenv"; \
		  $(PYTHON_VENV_PIP) install --upgrade pip >/dev/null 2>&1 || true; \
		  $(PYTHON_VENV_PIP) install -r config/requirements-testing.txt >/dev/null 2>&1 || true; \
		  $(PYTHON_VENV_PIP) install -r config/tools-requirements.txt >/dev/null 2>&1 || true; \
		  echo "â„¹ï¸  All dependencies installed in virtual environment (PEP 668 safe)." )


# Check and install PlatformIO if needed
check-pio:
	@echo "ğŸ” Checking PlatformIO..."
	@which pio >/dev/null 2>&1 || (echo "ğŸ“¦ Installing PlatformIO..." && pip3 install platformio && echo "âœ… PlatformIO installed")
	@echo "âœ… PlatformIO available"

# Check and install Arduino CLI if needed (for HIL testing)
check-arduino-cli:
	@echo "ğŸ” Checking Arduino CLI..."
	@which arduino-cli >/dev/null 2>&1 || (echo "âš ï¸ Arduino CLI not found. Install with: brew install arduino-cli (macOS) or see https://arduino.github.io/arduino-cli/")
	@echo "âœ… Arduino CLI check complete"

# Check and install npm/Node.js if needed (for Web UI)
check-npm:
	@echo "ğŸ” Checking npm/Node.js..."
	@which npm >/dev/null 2>&1 || (echo "ğŸ“¦ Installing Node.js and npm..." && \
		if command -v brew >/dev/null 2>&1; then \
			brew install node; \
		elif command -v apt-get >/dev/null 2>&1; then \
			curl -fsSL https://deb.nodesource.com/setup_lts.x | sudo -E bash - && sudo apt-get install -y nodejs; \
		elif command -v yum >/dev/null 2>&1; then \
			curl -fsSL https://rpm.nodesource.com/setup_lts.x | sudo bash - && sudo yum install -y nodejs; \
		else \
			echo "âŒ Unable to auto-install Node.js. Please install manually from https://nodejs.org/"; \
			exit 1; \
		fi)
	@echo "âœ… npm/Node.js available"

## Firmware Related Make Targets (Arduino Framework)

build: check-pio
	# Build ATmega32A firmware using Arduino Framework via PlatformIO
	pio run -e atmega32a

clean: check-pio
	# Clean Arduino Framework build artifacts
	pio run --target clean

upload: check-pio
	# Upload Arduino Framework firmware to ATmega32A via Arduino as ISP
	@echo "ğŸ”§ Setting up Arduino as ISP (auto-upload if needed)..."
	@python3 scripts/setup_arduino_isp.py || (echo "âŒ Failed to setup Arduino as ISP" && exit 1)
	@echo "âœ… Arduino as ISP is ready"
	@echo "ğŸ“¤ Uploading firmware to ATmega32A..."
	pio run -e atmega32a --target upload

monitor-device: check-deps
	# Monitor serial output from Arduino Test Harness
	python3 scripts/hil_cli.py monitor

upload-to-device:
	# Upload ATmega32A firmware using Arduino as ISP with safety checks
	@echo "ğŸ”§ Setting up Arduino as ISP (auto-upload if needed)..."
	@python3 scripts/setup_arduino_isp.py || (echo "âŒ Failed to setup Arduino as ISP" && exit 1)
	@echo "âœ… Arduino as ISP is ready"
	@echo "ğŸ“¤ Uploading firmware via HIL CLI..."
	python3 scripts/hil_cli.py upload

upload-harness: check-pio
	# Upload Arduino Test Harness firmware to Arduino
	cd test/acceptance/arduino_harness && pio run --target upload

setup-arduino-isp: check-deps
	# Setup Arduino as ISP (auto-upload ArduinoISP sketch if needed)
	$(PYTHON_VENV) scripts/setup_arduino_isp.py

check-arduino-isp: check-deps
	# Check if Arduino as ISP is ready (no upload)
	$(PYTHON_VENV) scripts/setup_arduino_isp.py --check-only

hardware-sandbox: check-deps check-pio check-arduino-cli
	@echo "ğŸ”§ Setting up HIL Hardware Sandbox Environment..."
	@echo "Step 1: Setting up Arduino as ISP (auto-upload if needed)..."
	@$(PYTHON_VENV) scripts/setup_arduino_isp.py || (echo "âŒ Failed to setup Arduino as ISP" && exit 1)
	@echo "âœ… Arduino as ISP is ready"

	@echo "Step 2: Building latest ATmega32A firmware..."
	@pio run -e atmega32a || (echo "âŒ Firmware build failed" && exit 1)
	@echo "âœ… ATmega32A firmware build successful"

	@echo "Step 3: Programming ATmega32A target via Arduino as ISP..."
	@pio run -e atmega32a -t upload || (echo "âŒ ATmega32A programming failed" && exit 1)
	@echo "âœ… ATmega32A programmed successfully"

	@echo "Step 4: Switching from Arduino ISP to Test Harness..."
	@echo "ğŸ“‹ Please perform the following hardware changes:"
	@echo "   1. Remove the capacitor from Arduino RESET line"
	@echo "   2. Connect Arduino Test Harness to target"
	@echo "   3. Ensure proper pin connections per docs/planning/pin-matrix.md"
	@read -p "Press Enter when hardware setup is complete..." dummy

	@echo "Step 5: Uploading Arduino Test Harness firmware..."
	@cd test/acceptance/arduino_harness && pio run --target upload || (echo "âŒ Test harness upload failed" && exit 1)
	@echo "âœ… Arduino Test Harness uploaded successfully"

	@echo "Step 6: Waiting for Arduino Test Harness to initialize..."
	@sleep 3

	@echo "Step 7: Launching HIL Sandbox CLI..."
	@echo "ğŸ¯ HIL Hardware Sandbox is ready!"
	@echo "   - ATmega32A programmed with latest firmware"
	@echo "   - Arduino Test Harness loaded and ready"
	@echo "   - HIL framework connected"
	@echo ""
	python3 test/acceptance/hil_framework/sandbox_cli.py


## Testing Make Targets - Aligned with Software Testing Standard

# Complete test suite per software testing standard (Unit â†’ Acceptance â†’ Integration)
test: check-deps check-pio validate-config test-unit test-acceptance test-integration generate-traceability-report
	@echo "âœ… Complete test suite executed per software testing standard"
	@echo "   - Configuration validation: HIL config integrity verified"
	@echo "   - Unit tests: Unity Test Framework with 85% coverage requirement"
	@echo "   - Acceptance tests: BDD scenarios via Behave + pytest HIL framework"
	@echo "   - Integration tests: HIL hardware validation"
	@echo "   - Traceability report: Coverage and requirements mapping generated"

# Configuration validation target
validate-config: check-deps
	@echo "ğŸ” Validating HIL configuration integrity..."
	@web-ui/venv/bin/python scripts/validate_hil_config.py
	@echo "âœ… Configuration validation complete"

# Generate comprehensive traceability and coverage reports
generate-traceability-report: check-deps
	@echo "ğŸ“Š Generating traceability and coverage reports..."
	@python3 scripts/generate_traceability_report.py --audit
	@echo "âœ… Traceability report generation complete"

# Traceability compliance validation
validate-traceability: check-deps
	@echo "ğŸ” Validating PRD-to-test traceability compliance..."
	@python3 scripts/validate_traceability_compliance.py
	@echo "âœ… Traceability compliance validation complete"

check-compliance: validate-traceability generate-traceability-report
	@echo "ğŸ¯ Running complete compliance validation..."
	@echo "âœ… All compliance checks passed - ready for enterprise deployment"

# Manage pending BDD scenarios
manage-pending-scenarios: check-deps
	@echo "ğŸ” Analyzing pending BDD scenarios..."
	@python3 scripts/manage_pending_scenarios.py
	@echo "âœ… Pending scenarios analysis complete"

# Update pending BDD scenarios with @pending tags
update-pending-scenarios: check-deps
	@echo "ğŸ“ Updating BDD scenarios with @pending tags..."
	@python3 scripts/manage_pending_scenarios.py --update
	@echo "âœ… Pending scenarios updated"

test-all: check-deps check-pio test-unit test-acceptance
	@echo "Running all tests..."

# CI Pipeline - Unit tests only (no hardware required)
# This make target should execute the unit tests and simulate a release as if the CI pipeline has completed successfully
# The `make ci` flow should be as follows:
#   1. `make ci`should execute the unit tests
#   2. `make ci` should generate the executive report from the unit test results and the results of the last acceptance test run
#   3. `make ci` should generate the coverage report from the unit test results
ci: check-deps check-pio validate-config test-unit generate-executive-report generate-coverage-report
	@echo "ğŸš€ CI Pipeline Complete - Unit Tests Only"
	@echo "âœ… Configuration validation: HIL config integrity verified"
		@echo "âœ… Unit tests: Unity Test Framework with 85% coverage requirement"
	@echo "âœ… Executive report: Generated from unit test results"
		@echo "âœ… Coverage report: Generated with 85% coverage requirement validation"
	@echo "ğŸ“Š Reports available in coverage/ and final/ directories"

# Full CI test suite per software testing standard (Unit â†’ Acceptance â†’ Integration)
ci-test: check-deps check-pio validate-config test-unit test-acceptance generate-release-artifacts
	@echo "Running complete CI test suite per software testing standard..."
	@echo "âœ… Configuration validation: HIL config integrity verified"
		@echo "âœ… Unit tests: Unity Test Framework with 85% coverage"
	@echo "âœ… Acceptance tests: BDD scenarios via Behave + pytest HIL framework"
	@echo "âœ… Integration tests: HIL hardware validation"
	@echo "âœ… Release artifacts: Generated per release format standard"

# Local CI pipeline simulation
ci-local: check-deps
	@echo "ğŸš€ Running local CI pipeline simulation..."
	@python3 scripts/ci_test_runner.py
	@echo "âœ… Local CI pipeline complete"

# Three-stage testing per software testing standard
test-unit: check-deps check-pio
	@echo "Stage 1: Unit Testing (Unity Native Environment for embedded C/C++ with 85% coverage)..."
	@echo "ğŸ§ª Running comprehensive Unity test suite with coverage reporting..."
	@python3 scripts/unity_coverage_runner.py
	@echo "ğŸ“Š Coverage reports available in coverage/ directory"
	@echo "âœ… Unity native unit tests completed with coverage analysis"

# Individual module testing targets
test-unit-communication: check-deps check-pio
	@echo "ğŸ§ª Running communication module unit tests..."
	@python3 scripts/unity_coverage_runner.py --module communication

test-unit-hal: check-deps check-pio
	@echo "ğŸ§ª Running HAL module unit tests..."
	@python3 scripts/unity_coverage_runner.py --module hal

test-unit-control: check-deps check-pio
	@echo "ğŸ§ª Running control module unit tests..."
	@python3 scripts/unity_coverage_runner.py --module control

test-unit-sonicator: check-deps check-pio
	@echo "ğŸ§ª Running sonicator module unit tests..."
	@python3 scripts/unity_coverage_runner.py --module sonicator
test-acceptance: check-deps check-pio check-arduino-cli web-ui-test-acceptance
	@echo "Stage 2: Acceptance Testing (BDD scenarios via Behave framework)..."
	@echo "ğŸ” Probing HIL hardware (soft-fail permitted)..."
	@HIL_OK=0; \
	PYTHONPATH=. $(PYTHON_VENV) test/acceptance/hil_framework/hil_controller.py --setup >/dev/null 2>&1 && HIL_OK=1 || HIL_OK=0; \
	if [ $$HIL_OK -eq 1 ]; then \
		echo "âœ… HIL available - running acceptance tests in HIL mode"; \
		PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance \
			--junit \
			--junit-directory=acceptance-junit \
			-D profile=hil \
			--tags=~@pending; \
	else \
		echo "ğŸ›   Attempting to program target and setup Arduino Test Harness per pin-matrix..."; \
		$(PYTHON_VENV) scripts/setup_arduino_isp.py >/dev/null 2>&1 || true; \
		pio run -e atmega32a >/dev/null 2>&1 || true; \
		pio run -e atmega32a -t upload >/dev/null 2>&1 || true; \
		( cd test/acceptance/arduino_harness && pio run --target upload ) >/dev/null 2>&1 || true; \
		sleep 3; \
		HIL_OK=0; PYTHONPATH=. $(PYTHON_VENV) test/acceptance/hil_framework/hil_controller.py --setup >/dev/null 2>&1 && HIL_OK=1 || HIL_OK=0; \
		if [ $$HIL_OK -eq 1 ]; then \
			echo "âœ… HIL available after auto-setup - running acceptance tests in HIL mode"; \
			PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance \
				--junit \
				--junit-directory=acceptance-junit \
				-D profile=hil \
				--tags=~@pending; \
		else \
			echo "âŒ HIL hardware not available - HIL testing is required"; \
			exit 1; \
		fi; \
	fi

test-integration: check-deps check-arduino-cli
	@echo "Stage 3: Integration Testing (HIL hardware validation for embedded systems)..."
	@python3 scripts/detect_hardware.py --check-arduino || (echo "âŒ Hardware required for integration tests" && exit 1)
	@echo "âœ… Hardware detected - running HIL integration tests..."
	python3 -m behave test/acceptance \
		--junit \
		--junit-directory=integration-junit \
		-D profile=integration \
		--tags=integration

# HIL Testing Targets
test-acceptance-hil: check-deps check-arduino-cli
	@echo "ğŸ§ª Running BDD acceptance tests with HIL hardware validation..."
	@$(PYTHON_VENV) scripts/detect_hardware.py --check-arduino || (echo "âŒ Hardware required for HIL testing" && exit 1)
	PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance --junit --junit-directory=acceptance-junit --tags=hil -D profile=hil

acceptance-setup: check-deps
	@echo "ğŸ”§ Setting up acceptance test framework..."
	PYTHONPATH=. $(PYTHON_VENV) -m test.acceptance.hil_framework.hil_controller --setup

acceptance-clean: check-deps
	@echo "ğŸ§¹ Cleaning acceptance test framework..."
	PYTHONPATH=. $(PYTHON_VENV) -m test.acceptance.hil_framework.hil_controller --cleanup

acceptance-test-basic: check-deps check-arduino-cli
	@echo "ğŸ”Œ Running basic acceptance connectivity tests..."
	PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance/features/hil_basic_connectivity.feature -D profile=hil

acceptance-test-gpio: check-deps check-arduino-cli
	@echo "ğŸ”§ Running acceptance GPIO functionality tests..."
	python3 test_acceptance_simple.py

acceptance-test-adc: check-deps check-arduino-cli
	@echo "ğŸ“Š Running acceptance ADC verification tests..."
	PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance/features/hil_adc_verification.feature -D profile=hil

acceptance-test-pwm: check-deps check-arduino-cli
	@echo "ğŸ“¡ Running acceptance PWM generation tests..."
	PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance/features/hil_pwm_generation.feature -D profile=hil

acceptance-test-modbus: check-deps check-arduino-cli
	@echo "ğŸ”— Running acceptance MODBUS communication tests..."
	PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance/features/hil_modbus_communication.feature -D profile=hil

acceptance-test-power: check-deps check-arduino-cli
	@echo "âš¡ Running acceptance power verification tests..."
	PYTHONPATH=. $(PYTHON_VENV) -m behave test/acceptance/features/hil_power_verification.feature -D profile=hil

# Quick hardware timing validation (Emergency Stop <= 100ms)
test-hil-timing: check-deps check-arduino-cli check-pio
	@echo "â±  Running emergency-stop timing validation (requires Arduino Test Wrapper)..."
	@if [ -n "$(ARDUINO_PORT)" ]; then \
		PYTHONPATH=. $(PYTHON_VENV) test/hil/run_emergency_stop_timing.py --port "$(ARDUINO_PORT)" || exit $$?; \
	else \
		PYTHONPATH=. $(PYTHON_VENV) test/hil/run_emergency_stop_timing.py || exit $$?; \
	fi
	@echo "âœ… Timing validation complete"

# ISP programming smoke test (Arduino as ISP â†’ ATmega32A)
isp-smoke-test: check-deps check-arduino-cli check-pio
	@echo "ğŸ”Œ Running ISP programming smoke test (non-interactive)..."
	@if [ -n "$(ARDUINO_PORT)" ]; then \
		PYTHONPATH=. $(PYTHON_VENV) test/hil/isp_smoke_test.py --port "$(ARDUINO_PORT)" --non-interactive || exit $$?; \
	else \
		PYTHONPATH=. $(PYTHON_VENV) test/hil/isp_smoke_test.py --non-interactive || exit $$?; \
	fi
	@echo "âœ… ISP smoke test complete"

generate-release-artifacts: check-deps
	@echo "Generating release format compliant artifacts..."
	python3 scripts/release/generate_executive_report.py \
		--acceptance-results=acceptance-junit \
		--integration-results=integration-junit \
		--unit-results=unit-test-results.xml \
		--coverage=coverage.json \
		--output=final
	@echo "âœ… Release artifacts generated in final/"


# # # # RELEASE AND REPORTING MAKE TARGETS # # # #

# Generate executive report for CI pipeline (unit tests only)
# This make target should generate the executive report from the latest test results and coverage data.
# This report should always adhere to the company standards outlined in the `docs/sop/release-format.md`, and `docs/sop/executive-report-standard.md`
generate-executive-report: check-deps
	@echo "ğŸ“Š Generating executive report for CI pipeline..."
	@mkdir -p final
	@python3 scripts/generate_unit_executive_report.py \
		--unit-results=coverage/coverage.json \
		--coverage=coverage/coverage.json \
		--output=final
	@echo "âœ… Executive report generated in final/"

# Generate coverage report for CI pipeline
generate-coverage-report: check-deps
	@echo "ğŸ“Š Generating coverage report..."
	@python3 scripts/generate_coverage_summary.py \
		--input=coverage/coverage.json \
		--output=final/coverage-summary.json
	@echo "âœ… Coverage report generated in final/"

# Standalone coverage target (readable summary)
coverage: check-deps
	@echo "ğŸ“Š Running coverage pipeline (unit tests + summary)..."
	@$(MAKE) test-unit
	@$(MAKE) generate-coverage-report
	@echo "ğŸ“„ Coverage summary: final/coverage-summary.json"
	@echo "ğŸ“‚ Full artifacts: coverage/ and final/"

# Generate complete executive report (manual testing with acceptance results)
generate-complete-executive-report: check-deps
	@echo "ğŸ“Š Generating complete executive report (unit + acceptance)..."
	@mkdir -p final
	@python3 scripts/generate_complete_executive_report.py \
		--unit-results=final/executive-report.json \
		--acceptance-results=final/acceptance-report.json \
		--output=final
	@echo "âœ… Complete executive report generated in final/"
	@echo "ğŸ“‹ Note: Ensure acceptance tests have been run manually and acceptance-report.json exists"



# # # # WEB USER INTERFACE MAKE TARGETS # # # #

# Install Web UI dependencies
web-ui-install:
	@echo "ğŸ“¦ Installing Web UI dependencies..."
	@echo "ğŸ“¦ Installing frontend dependencies..."
	@cd web-ui/frontend && npm install --legacy-peer-deps || (echo "âŒ Frontend dependency installation failed" && exit 1)
	@echo "ğŸ“¦ Installing backend dependencies..."
	@cd web-ui/backend && npm install --legacy-peer-deps || (echo "âŒ Backend dependency installation failed" && exit 1)
	@echo "ğŸ“¦ Installing Python test dependencies..."
	@if [ ! -d "web-ui/venv" ]; then \
		python3 -m venv web-ui/venv || (echo "âŒ Python venv creation failed" && exit 1); \
	fi
	@web-ui/venv/bin/python -m pip install --upgrade pip >/dev/null 2>&1
	@web-ui/venv/bin/python -m pip install pytest pytest-asyncio pytest-mock requests websocket-client pytest-cov || (echo "âŒ Python test dependencies installation failed" && exit 1)
	@echo "âœ… Web UI dependencies installed successfully"

# Development mode - start both frontend and backend
web-ui-dev: web-ui-install web-ui-build
	@echo "ğŸš€ Starting Web UI in development mode..."
	@echo "ğŸ”§ Checking HARDWARE_PRESENT environment variable..."
	@if [ -z "$(HARDWARE_PRESENT)" ]; then \
		echo "âš ï¸  HARDWARE_PRESENT not set, defaulting to simulation mode (HARDWARE_PRESENT=false)"; \
		export HARDWARE_PRESENT=false; \
	fi
	@echo "ğŸ”§ HARDWARE_PRESENT=$(HARDWARE_PRESENT) -> $(shell [ "$(HARDWARE_PRESENT)" = "true" ] && echo "Hardware Mode" || echo "Simulation Mode")"
	@echo "ğŸ”§ Cleaning up any processes on ports 3001 and 3101..."
	@lsof -ti:3001 | xargs -r kill -9 2>/dev/null || true
	@lsof -ti:3101 | xargs -r kill -9 2>/dev/null || true
	@sleep 2
	@echo "ğŸ”§ Starting backend server on port 3001..."
	@cd web-ui/backend && HARDWARE_PRESENT=$(HARDWARE_PRESENT) PORT=3001 npm run dev &
	@echo "ğŸ”§ Starting frontend development server on port 3101..."
	@cd web-ui/frontend && PORT=3101 npm run dev &
	@echo "â³ Waiting for servers to initialize..."
	@sleep 8
	@echo "ğŸ” Checking server status..."
	@curl -s http://localhost:3001/api/health > /dev/null 2>&1 || echo "âš ï¸ Backend server may not be ready yet"
	@curl -s http://localhost:3101 > /dev/null 2>&1 || echo "âš ï¸ Frontend server may not be ready yet"
	@echo "âœ… Web UI development servers started"
	@echo "ğŸ“± Frontend: http://localhost:3101"
	@echo "ğŸ”Œ Backend API: http://localhost:3001/api"
	@echo "ğŸ”— WebSocket: ws://localhost:3001/ws"
	@echo "ğŸ¯ Mode: $(shell [ "$(HARDWARE_PRESENT)" = "true" ] && echo "Hardware Connected" || echo "Simulation Mode")"

# Production build
web-ui-build:
	@echo "ğŸ—ï¸ Building Web UI for production..."
	@echo "ğŸ—ï¸ Building backend..."
	cd web-ui/backend && npm run build
	@echo "ğŸ—ï¸ Building frontend..."
	cd web-ui/frontend && npm run build
	@echo "âœ… Web UI production build complete"

# Sandbox mode - build firmware, upload to DUT, then start web UI
# The Web User Interface Sandbox make target should launch a fully functioning Sandbox mode for our user interface
# The web-ui-sandbox make target flow should be as follows:
#    1. Build latest production firmware (PlatformIO production environment) (make build)
#    2. Automatically detect the port that the Arduino is connected to (scripts/detect_hardware.py)
#    3. Upload the Arduino as ISP sketch to the arduino using the automatically detected port.
#    4. Upload the latest production firmware to the ATmega32A (DUT) using the Arduino as ISP (make upload-to-device)
#    5. Upload the latest version of the Arduino Test Harness sketch to the Arduino (make upload-harness)
#    6. Verify that the test harness has been uploaded successfully (make verify-harness)
#    7. Start the Web User Interface in sandbox mode
#        - Start the Web User Interface backend with HIL integration, this should directly integrate with our HIL framework
#        - Start the Web User Interface frontend and verify that it is running
#    8. Open the web interface in the default browser
#    9. Verify that the web interface is running and that the HIL framework is integrated
web-ui-sandbox: check-deps check-pio check-arduino-cli
	@echo "ğŸ§ª Starting Web UI in sandbox mode..."
	@echo ""
	@echo "Step 1: Setting up Arduino as ISP (auto-upload if needed)..."
	@ARDUINO_PORT=$$(python3 scripts/setup_arduino_isp.py --get-port 2>/dev/null || python3 scripts/detect_hardware.py --check-arduino 2>&1 | grep "Found Arduino" | sed 's/.*Found Arduino programmer: //' || echo "/dev/cu.usbmodem2101"); \
	echo "Detected Arduino port: $$ARDUINO_PORT"; \
	export ARDUINO_PORT=$$ARDUINO_PORT; \
	python3 scripts/setup_arduino_isp.py || (echo "âŒ Failed to setup Arduino as ISP" && exit 1)
	@echo "âœ… Arduino as ISP is ready"

	@echo ""
	@echo "Step 2: Building latest production firmware..."
	@export ARDUINO_PORT=$$ARDUINO_PORT; \
	pio run -e atmega32a || (echo "âŒ Firmware build failed" && exit 1)
	@echo "âœ… Production firmware build successful"

	@echo ""
	@echo "Step 3: Programming ATmega32A target via Arduino as ISP..."
	@export ARDUINO_PORT=$$ARDUINO_PORT; \
	pio run -e atmega32a -t upload || (echo "âŒ ATmega32A programming failed" && exit 1)
	@echo "âœ… ATmega32A programmed successfully"

	@echo ""
	@echo "Step 4: Auto-configuring for Test Harness mode..."
	@echo "âš ï¸ Assuming hardware is already configured for test harness"
	@echo "ğŸ“‹ Expected configuration: Arduino Test Harness â†” ATmega32A DUT"

	@echo ""
	@echo "Step 5: Uploading Arduino Test Harness firmware..."
	@cd test/acceptance/hil_framework/arduino_harness && pio run --target upload || (echo "âŒ Test harness upload failed - continuing anyway" && sleep 1)
	@echo "âœ… Arduino Test Harness upload attempted"

	@echo ""
	@echo "Step 6: Waiting for Arduino Test Harness to initialize..."
	@sleep 3

	@echo ""
	@echo "Step 7: Verifying HIL hardware connection..."
	@cd test/acceptance && python3 -m hil_framework.hil_controller --setup || (echo "âš ï¸ HIL hardware not detected - continuing anyway" && sleep 1)

	@echo ""
	@echo "Step 8: Starting Web UI servers..."
	@echo "ğŸ”§ Cleaning up any processes on ports 3001 and 3101..."
	@lsof -ti:3001 | xargs -r kill -9 2>/dev/null || true
	@lsof -ti:3101 | xargs -r kill -9 2>/dev/null || true
	@sleep 2
	@echo "ğŸ”§ Starting Web UI backend with HIL integration..."
	@cd web-ui/backend && PORT=3001 npm run dev > /tmp/web-ui-backend.log 2>&1 &
	@echo "ğŸ”§ Starting Web UI frontend..."
	@cd web-ui/frontend && PORT=3101 npm run dev > /tmp/web-ui-frontend.log 2>&1 &
	@echo "â³ Waiting for servers to start..."
	@sleep 8
	@echo "ğŸ” Checking server status..."
	@curl -s http://localhost:3001/api/health > /dev/null 2>&1 || echo "âš ï¸ Backend server may not be ready yet"
	@curl -s http://localhost:3101 > /dev/null 2>&1 || echo "âš ï¸ Frontend server may not be ready yet"

	@echo ""
	@echo "âœ… Web UI sandbox mode active"
	@echo "ğŸ“± Web Interface: http://localhost:3101"
	@echo "ğŸ”Œ Backend API: http://localhost:3001/api"
	@echo "ğŸ”— WebSocket: ws://localhost:3001/ws"
	@echo "ğŸ¯ Hardware: Arduino Test Harness â†” ATmega32A DUT"
	@echo "ğŸ“‹ Pin mapping: docs/planning/pin-matrix.md (SOLE SOURCE OF TRUTH)"
	@echo ""
	@echo "ğŸš€ Opening web interface in default browser..."
	@sleep 2
	@open http://localhost:3101 2>/dev/null || xdg-open http://localhost:3101 2>/dev/null || echo "Please open http://localhost:3101 in your browser"

# Automated sandbox mode - skips hardware setup prompt (for CI/CD)
web-ui-sandbox-auto: check-deps check-pio check-arduino-cli
	@echo "ğŸ§ª Starting Web UI in automated sandbox mode..."
	@echo ""
	@echo "Step 1: Setting up Arduino as ISP (auto-upload if needed)..."
	@python3 scripts/setup_arduino_isp.py || (echo "âŒ Failed to setup Arduino as ISP" && exit 1)
	@echo "âœ… Arduino as ISP is ready"

	@echo ""
	@echo "Step 2: Building latest production firmware..."
	@pio run -e atmega32a || (echo "âŒ Firmware build failed" && exit 1)
	@echo "âœ… Production firmware build successful"

	@echo ""
	@echo "Step 3: Programming ATmega32A target via Arduino as ISP..."
	@pio run -e atmega32a -t upload || (echo "âŒ ATmega32A programming failed" && exit 1)
	@echo "âœ… ATmega32A programmed successfully"

	@echo ""
	@echo "Step 4: Auto-configuring for Test Harness mode..."
	@echo "âš ï¸ Assuming hardware is already configured for test harness"
	@echo "ğŸ“‹ Expected configuration: Arduino Test Harness â†” ATmega32A DUT"

	@echo ""
	@echo "Step 5: Uploading Arduino Test Harness firmware..."
	@cd test/acceptance/hil_framework/arduino_harness && pio run --target upload || (echo "âŒ Test harness upload failed - continuing anyway" && sleep 1)
	@echo "âœ… Arduino Test Harness upload attempted"

	@echo ""
	@echo "Step 6: Waiting for Arduino Test Harness to initialize..."
	@sleep 3

	@echo ""
	@echo "Step 7: Verifying HIL hardware connection..."
	@cd test/acceptance && python3 -m hil_framework.hil_controller --setup || (echo "âš ï¸ HIL hardware not detected - continuing anyway" && sleep 1)

	@echo ""
	@echo "Step 8: Starting Web UI servers..."
	@echo "ğŸ”§ Starting Web UI backend with HIL integration..."
	@cd web-ui/backend && npm run dev &
	@echo "ğŸ”§ Starting Web UI frontend..."
	@cd web-ui/frontend && npm run dev &
	@echo "â³ Waiting for servers to start..."
	@sleep 5

	@echo ""
	@echo "âœ… Web UI automated sandbox mode active"
	@echo "ğŸ“± Web Interface: http://localhost:3000"
	@echo "ğŸ”Œ Backend API: http://localhost:3001/api"
	@echo "ğŸ”— WebSocket: ws://localhost:3001/ws"
	@echo "ğŸ¯ Hardware: Arduino Test Harness â†” ATmega32A DUT"
	@echo "ğŸ“‹ Pin mapping: docs/planning/pin-matrix.md (SOLE SOURCE OF TRUTH)"

# Run Web UI unit tests
web-ui-test: check-deps
	@echo "ğŸ§ª Running Web UI unit tests..."
	@cd web-ui && \
		../web-ui/venv/bin/python -m pytest tests/ -v --cov=backend/src --cov-report=term-missing --cov-report=html:htmlcov --cov-fail-under=85 2>/dev/null || \
		. ./venv/bin/activate && python -m pytest tests/ -v --cov=backend/src --cov-report=term-missing --cov-report=html:htmlcov --cov-fail-under=85
	@echo "âœ… Web UI unit tests completed"

# Run Web UI acceptance tests
web-ui-test-acceptance: check-deps web-ui-install
	@echo "ğŸ§ª Running Web UI acceptance tests..."
	@echo "ğŸ”§ Installing Python dependencies for web-ui acceptance testing..."
	@$(PYTHON_VENV_PIP) install selenium chromedriver-autoinstaller behave requests >/dev/null 2>&1 || \
		echo "âš ï¸ Some dependencies may not be available - continuing anyway"
	@echo "ğŸŒ Starting web-ui acceptance test suite..."
	@cd web-ui/test/acceptance && \
		PYTHONPATH=. $(VENV_PY) -m behave \
			--junit \
			--junit-directory=../../results \
			-D simulation_mode=true \
			-D headless=true \
			--tags=~@skip \
			--format=pretty \
			--outfile=../../results/web-ui-acceptance-output.txt \
			features/ || echo "âš ï¸ Some web-ui acceptance tests may have failed"
	@echo "âœ… Web UI acceptance tests completed"
	@echo "ğŸ“Š Results available in web-ui/results/"

# Stop Web UI development servers
web-ui-stop:
	@echo "ğŸ›‘ Stopping Web UI development servers..."
	@echo "ğŸ”§ Terminating Node.js processes (vite, nodemon, ts-node)..."
	@pkill -f "vite\|nodemon\|ts-node" 2>/dev/null || true
	@echo "ğŸ”§ Force killing processes on ports 3001 and 3101..."
	@lsof -ti:3001,3101 | xargs kill -9 2>/dev/null || true
	@sleep 1
	@echo "âœ… Web UI development servers stopped"

# Clean Web UI build artifacts
web-ui-clean:
	@echo "ğŸ§¹ Cleaning Web UI build artifacts..."
	rm -rf web-ui/frontend/dist
	rm -rf web-ui/frontend/node_modules
	rm -rf web-ui/backend/dist
	rm -rf web-ui/backend/node_modules
	rm -rf web-ui/venv
	rm -rf web-ui/htmlcov
	rm -rf web-ui/.pytest_cache
	@echo "âœ… Web UI cleaned"

## Docker Web UI Targets

# Build Docker images for Web UI
web-ui-docker-build:
	@echo "ğŸ³ Building Web UI Docker images..."
	@echo "ğŸ—ï¸ Building backend image..."
	cd web-ui && docker-compose build backend
	@echo "ğŸ—ï¸ Building frontend image..."
	cd web-ui && docker-compose build frontend
	@echo "âœ… Web UI Docker images built"

# Start Web UI in Docker development mode
web-ui-docker-dev:
	@echo "ğŸ³ Starting Web UI in Docker development mode..."
	cd web-ui && docker-compose up -d
	@echo "â³ Waiting for services to start..."
	@sleep 10
	@echo "âœ… Web UI Docker development environment started"
	@echo "ğŸ“± Frontend: http://localhost:3101"
	@echo "ğŸ”Œ Backend API: http://localhost:3001/api"
	@echo "ğŸ“Š Health Check: http://localhost:3001/api/health"

# Start Web UI in Docker production mode
web-ui-docker-prod:
	@echo "ğŸ³ Starting Web UI in Docker production mode..."
	cd web-ui && docker-compose -f docker-compose.prod.yml up -d
	@echo "â³ Waiting for services to start..."
	@sleep 15
	@echo "âœ… Web UI Docker production environment started"
	@echo "ğŸ“± Frontend: http://localhost:3101"
	@echo "ğŸ”Œ Backend API: http://localhost:3001/api"
	@echo "ğŸ“Š Health Check: http://localhost:3001/api/health"

# Stop Web UI Docker containers
web-ui-docker-stop:
	@echo "ğŸ³ Stopping Web UI Docker containers..."
	cd web-ui && docker-compose down || true
	cd web-ui && docker-compose -f docker-compose.prod.yml down || true
	@echo "âœ… Web UI Docker containers stopped"

# Clean Web UI Docker resources
web-ui-docker-clean: web-ui-docker-stop
	@echo "ğŸ³ Cleaning Web UI Docker resources..."
	cd web-ui && docker-compose down --volumes --remove-orphans || true
	cd web-ui && docker-compose -f docker-compose.prod.yml down --volumes --remove-orphans || true
	@echo "ğŸ—‘ï¸ Removing Web UI Docker images..."
	docker rmi multi-sonicator-backend-dev multi-sonicator-frontend-dev 2>/dev/null || true
	docker rmi multi-sonicator-backend-prod multi-sonicator-frontend-prod 2>/dev/null || true
	@echo "ğŸ§¹ Pruning unused Docker resources..."
	docker system prune -f
	@echo "âœ… Web UI Docker resources cleaned"

## Company Standards Management

# Download/update company standards from central repository (standards only)
update-standards:
	@python3 scripts/sync_company_standards.py

# Alias for update-standards
sync-standards: update-standards

# Check if standards are up to date
check-standards:
	@python3 scripts/sync_company_standards.py --check-only

## Development Tools Management

# Update development tools to latest versions
update-tools: check-deps
	@echo "ğŸ”„ Updating development tools..."
	@$(PYTHON_VENV_PIP) install --upgrade -r config/tools-requirements.txt
	@echo "âœ… Development tools updated"
	@echo "â„¹ï¸ Remember to activate the virtual environment with: source web-ui/venv/bin/activate"

# Install development tools
install-tools: check-deps
	@echo "ğŸ“¦ Installing development tools..."
	@$(PYTHON_VENV_PIP) install -r config/tools-requirements.txt
	@echo "âœ… Development tools installed"
	@echo "â„¹ï¸ Remember to activate the virtual environment with: source web-ui/venv/bin/activate"

# Check development tools installation
check-tools: check-deps
	@echo "ğŸ” Checking development tools..."
	@$(PYTHON_VENV) -c "import gemini" 2>/dev/null && \
	echo "âœ… All development tools available" || \
	( echo "âš ï¸ Some development tools missing; installing..." && \
	  make install-tools )

# Run a development tool command within the virtual environment
run-tool: check-tools
	@if [ -z "$(TOOL)" ]; then \
		echo "âŒ ERROR: TOOL parameter required. Usage: make run-tool TOOL=gemini-cli"; \
		exit 1; \
	fi
	@echo "ğŸ”§ Running $(TOOL) in virtual environment..."
	@web-ui/venv/bin/$(TOOL) $(ARGS)

## CI/CD Pipeline Artifact Management
upload-artifacts: check-deps
	@echo "ğŸ“¦ Packaging and uploading CI/CD artifacts..."
	@mkdir -p artifacts/firmware artifacts/reports artifacts/coverage
	@echo "ğŸ”„ Collecting firmware artifacts..."
	@if [ -d ".pio/build" ]; then \
		cp -r .pio/build/* artifacts/firmware/ 2>/dev/null || true; \
	fi
	@echo "ğŸ”„ Collecting test reports..."
	@if [ -d "reports" ]; then \
		cp -r reports/* artifacts/reports/ 2>/dev/null || true; \
	fi
	@echo "ğŸ”„ Collecting coverage reports..."
	@if [ -d "coverage" ]; then \
		cp -r coverage/* artifacts/coverage/ 2>/dev/null || true; \
	fi
	@echo "ğŸ”„ Generating artifact manifest..."
	@python3 scripts/ci/generate_reports.py --build-dir .pio/build --output-dir artifacts/reports
	@echo "ğŸ“Š Creating artifact checksums..."
	@find artifacts -type f -exec sha256sum {} \; > artifacts/checksums.sha256
	@echo "âœ… Artifacts packaged successfully in artifacts/ directory"
	@echo "ğŸ“‹ Artifact summary:"
	@find artifacts -type f | wc -l | xargs echo "  Total files:"
	@du -sh artifacts | cut -f1 | xargs echo "  Total size:"

# ============================================================================
# DEFINITION OF DONE (DoD) VALIDATION TARGETS - MANDATORY QUALITY GATES
# ============================================================================

# Validate DoD compliance for a specific story
validate-dod:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make validate-dod STORY=1.3"; \
		exit 1; \
	fi
	@echo "ğŸ” Validating Definition of Done compliance for Story $(STORY)..."
	@echo "ğŸ“‹ Checking DoD checklist completion..."
	@STORY_FILE=$$(for f in docs/agile/stories/$(STORY)*.md docs/agile/stories/$(STORY)*.md; do \
		[ -f "$$f" ] && { echo "$$f"; break; }; \
	done); \
	if [ -z "$$STORY_FILE" ]; then \
		echo "âŒ ERROR: Story file not found for $(STORY) (searched docs/agile/stories and docs/agile/stories)"; \
		exit 1; \
	fi
	@echo "ğŸ“„ Using story file: $$STORY_FILE"; \
	if ! grep -q "## Definition of Done Checklist Completion" "$$STORY_FILE"; then \
		echo "âŒ BLOCKING: DoD checklist section missing in $$STORY_FILE"; \
		echo "ğŸ“‹ Required: Add DoD checklist using docs/sop/definition-of-done-template.md"; \
		exit 1; \
	fi
	@echo "âœ… DoD checklist section found"
	@STORY_FILE=$$(for f in docs/agile/stories/$(STORY)*.md docs/agile/stories/$(STORY)*.md; do \
		[ -f "$$f" ] && { echo "$$f"; break; }; \
	done); \
	if ! grep -q "## QA Results" "$$STORY_FILE"; then \
		echo "âŒ BLOCKING: QA Results section missing - Test Architect review required"; \
		echo "ğŸ“‹ Required: Run Test Architect review using *review $(STORY) command"; \
		exit 1; \
	fi
	@echo "âœ… QA Results section found"
	@if [ ! -f "docs/qa/gates/$(STORY)"*.yml ]; then \
		echo "âŒ BLOCKING: Quality gate file missing"; \
		echo "ğŸ“‹ Required: Test Architect must create quality gate using *gate $(STORY) command"; \
		exit 1; \
	fi
	@echo "âœ… Quality gate file found"
	@GATE_FILE=$$(ls docs/qa/gates/$(STORY)*.yml 2>/dev/null | head -1); \
	GATE_STATUS=$$(grep "^gate:" "$$GATE_FILE" | cut -d' ' -f2); \
	if [ "$$GATE_STATUS" != "PASS" ]; then \
		echo "âŒ BLOCKING: Quality gate status is $$GATE_STATUS (must be PASS)"; \
		echo "ğŸ“‹ Required: Resolve quality issues before marking story as Done"; \
		exit 1; \
	fi
	@echo "âœ… Quality gate status: PASS"
	@echo "ğŸ¯ DoD validation PASSED for Story $(STORY)"

# Check DoD compliance across all completed stories
check-dod-compliance:
	@echo "ğŸ” Checking DoD compliance across all stories marked as Done..."
	@FAILED_STORIES=""; \
	for story_file in docs/agile/stories/*.md docs/agile/stories/*.md; do \
		if grep -q "^Done$$\|^Complete$$\|^Ready for Review$$" "$$story_file"; then \
			STORY_ID=$$(basename "$$story_file" .md | cut -d'.' -f1-2); \
			echo "ğŸ“‹ Checking $$STORY_ID..."; \
			if ! make validate-dod STORY=$$STORY_ID >/dev/null 2>&1; then \
				echo "âŒ DoD compliance FAILED for $$STORY_ID"; \
				FAILED_STORIES="$$FAILED_STORIES $$STORY_ID"; \
			else \
				echo "âœ… DoD compliance PASSED for $$STORY_ID"; \
			fi; \
		fi; \
	done; \
	if [ -n "$$FAILED_STORIES" ]; then \
		echo "âŒ BLOCKING: DoD compliance failures detected:$$FAILED_STORIES"; \
		echo "ğŸ“‹ Required: Complete DoD checklist for all failed stories"; \
		exit 1; \
	fi
	@echo "ğŸ¯ All completed stories pass DoD compliance checks"

# Enforce DoD gate before allowing story completion
enforce-dod-gate:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make enforce-dod-gate STORY=1.3"; \
		exit 1; \
	fi
	@echo "ğŸš« ENFORCING DoD quality gate for Story $(STORY)..."
	@echo "âš ï¸  This is a MANDATORY quality gate - no bypassing allowed"
	@make validate-dod STORY=$(STORY)
	@echo "ğŸ”’ DoD quality gate ENFORCED - Story $(STORY) approved for completion"

# Validate story completion readiness
validate-story-completion:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make validate-story-completion STORY=1.3"; \
		exit 1; \
	fi
	@echo "ğŸ¯ Validating story completion readiness for Story $(STORY)..."
	@make enforce-dod-gate STORY=$(STORY)
	@make test-unit >/dev/null 2>&1 || (echo "âŒ BLOCKING: Unit tests failing"; exit 1)
	@echo "âœ… Unit tests passing"
	@echo "ğŸ¯ Story $(STORY) is READY for completion - all quality gates passed"

# ============================================================================
# QA COMMAND WRAPPERS (Quinn QA CLI)
# ============================================================================
.PHONY: qa-help qa-gate qa-review qa-nfr-assess qa-risk-profile qa-test-design qa-trace

# Show QA CLI commands
qa-help:
	@python3 scripts/qa_cli.py help

# Create/update a quality gate file for a story
# Usage: make qa-gate STORY=1.4 STATUS=PASS REASON="Short rationale"
qa-gate:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make qa-gate STORY=1.4 STATUS=PASS [REASON=...]"; \
		exit 1; \
	fi
	@if [ -z "$(STATUS)" ]; then \
		echo "âŒ ERROR: STATUS parameter required. One of: PASS|CONCERNS|FAIL|WAIVED"; \
		exit 1; \
	fi
	@echo "ğŸ§ª Creating/updating QA gate for story $(STORY) with status $(STATUS)..."
	@python3 scripts/qa_cli.py gate "$(STORY)" --status "$(STATUS)" --reason "$(REASON)"
	@echo "âœ… QA gate updated"

# Placeholders for additional QA flows (will exit with a helpful message until implemented)
# Usage: make qa-review STORY=1.4
qa-review:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make qa-review STORY=1.4"; \
		exit 1; \
	fi
	@python3 scripts/qa_cli.py review "$(STORY)" || (echo "â„¹ï¸ review command not yet implemented in scripts/qa_cli.py" && exit 1)

# Usage: make qa-nfr-assess STORY=1.4
qa-nfr-assess:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make qa-nfr-assess STORY=1.4"; \
		exit 1; \
	fi
	@python3 scripts/qa_cli.py nfr-assess "$(STORY)" || (echo "â„¹ï¸ nfr-assess command not yet implemented in scripts/qa_cli.py" && exit 1)

# Usage: make qa-risk-profile STORY=1.4
qa-risk-profile:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make qa-risk-profile STORY=1.4"; \
		exit 1; \
	fi
	@python3 scripts/qa_cli.py risk-profile "$(STORY)" || (echo "â„¹ï¸ risk-profile command not yet implemented in scripts/qa_cli.py" && exit 1)

# Usage: make qa-test-design STORY=1.4
qa-test-design:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make qa-test-design STORY=1.4"; \
		exit 1; \
	fi
	@python3 scripts/qa_cli.py test-design "$(STORY)" || (echo "â„¹ï¸ test-design command not yet implemented in scripts/qa_cli.py" && exit 1)

# Usage: make qa-trace STORY=1.4
qa-trace:
	@if [ -z "$(STORY)" ]; then \
		echo "âŒ ERROR: STORY parameter required. Usage: make qa-trace STORY=1.4"; \
		exit 1; \
	fi
	@python3 scripts/qa_cli.py trace "$(STORY)" || (echo "â„¹ï¸ trace command not yet implemented in scripts/qa_cli.py" && exit 1)
## =============================================================================
## PROJECT BOARD UPDATER
## =============================================================================
.PHONY: update-project-board
update-project-board:
	@echo "ğŸ”„ Updating project board and story status dashboard..."
	@python3 scripts/update_project_board.py
	@echo "âœ… Project board updated"

## =============================================================================
## DOCUMENTATION BUILD TARGETS
## =============================================================================
.PHONY: docs-all check-doxygen docs-firmware docs-web-backend docs-web-frontend docs-all

# Ensure Doxygen is available and give installation guidance if missing
check-doxygen:
	@echo "ğŸ” Checking Doxygen..."
	@which doxygen >/dev/null 2>&1 || ( \
		echo "âš ï¸ Doxygen not found. Installing..."; \
		if command -v brew >/dev/null 2>&1; then \
			brew install doxygen graphviz; \
		elif command -v apt-get >/dev/null 2>&1; then \
			sudo apt-get update && sudo apt-get install -y doxygen graphviz; \
		elif command -v yum >/dev/null 2>&1; then \
			sudo yum install -y doxygen graphviz; \
		else \
			echo "âŒ Unable to auto-install. Please install manually:"; \
			echo "   macOS: brew install doxygen graphviz"; \
			echo "   Ubuntu/Debian: sudo apt-get install doxygen graphviz"; \
			echo "   Or download from: https://www.doxygen.nl/download.html"; \
			exit 1; \
		fi \
	)
	@echo "âœ… Doxygen available"

# Build firmware docs with Doxygen
docs-firmware: check-doxygen
	@echo "ğŸ“š Building firmware documentation (Doxygen)..."
	@doxygen docs/doxygen/Doxyfile
	@echo "âœ… Firmware docs built in docs/site/firmware"

# Build backend docs with TypeDoc
docs-web-backend: check-doxygen
	@echo "ğŸ“š Building web-ui backend documentation (TypeDoc)..."
	@cd web-ui/backend && npx --yes typedoc
	@echo "âœ… Backend docs built in docs/site/web/backend"

# Build frontend docs with TypeDoc
docs-web-frontend: check-doxygen
	@echo "ğŸ“š Building web-ui frontend documentation (TypeDoc)..."
	@cd web-ui/frontend && npx --yes typedoc
	@echo "âœ… Frontend docs built in docs/site/web/frontend"

# Build all docs
docs-all: check-doxygen docs-firmware docs-web-backend docs-web-frontend
	@echo "ğŸ‰ All documentation generated under docs/site/"

# Compute documentation coverage and enforce no-drop against baseline
doc-coverage: check-doxygen
	@echo "ğŸ“Š Checking documentation coverage (no drop gate)..."
	@python3 scripts/doc_coverage_check.py \
		--baseline docs/coverage/doc_coverage_baseline.json \
		--min-firmware 0.0 --min-backend 0.0 --min-frontend 0.0 
	@echo "âœ… Documentation coverage check completed"
